{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from itertools import product\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder, DatasetFolder\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Stimuli For Imagenet Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Stimuli\n",
    "\n",
    "#savedir = '/Users/akshay/proj/psych209/attention/imagenet_stimuli'\n",
    "imagenet_path = '/scratch/groups/jlg/imagenet'\n",
    "savedir = '/scratch/users/akshayj/att_net_stimuli'\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "\n",
    "labels = ['elephant', 'leopard', 'truck', 'plane']\n",
    "\n",
    "def generate_stimuli(nObjectsPerImg=4, savedir=savedir, nStims=100, imsz=256):\n",
    "    all_locs = np.array(list(product(np.arange(imsz/128)*128, np.arange(imsz/128)*128)))\n",
    "\n",
    "    meta5 = dict()\n",
    "    for j in range(nStims):\n",
    "        \n",
    "        if j % 500 == 0:\n",
    "            print('Stimulus {}'.format(j))\n",
    "        \n",
    "        background = np.zeros((imsz,imsz,3),dtype=np.uint8) + 128 # grayscale background\n",
    "        loc_ind = np.random.choice(len(all_locs), size=(nObjectsPerImg,), replace=False)\n",
    "\n",
    "        meta5[j+1] = dict()\n",
    "\n",
    "        # Randomly select N objects per image, and extract them from the pickle.\n",
    "        img_ind = []\n",
    "        lbls = np.random.permutation(labels)\n",
    "        for i in range(nObjectsPerImg):\n",
    "            \n",
    "            cat1 = os.listdir(imagenet_path +'/'+lbls[i])\n",
    "            img_ind.append(lbls[i]+'/'+np.random.choice(cat1))\n",
    "            img = np.array(Image.open(imagenet_path+'/'+img_ind[-1]).resize((128,128)))\n",
    "            \n",
    "            if len(img.shape) < 3:\n",
    "                img = np.stack((img,)*3, axis=-1)\n",
    "\n",
    "            loc = all_locs[loc_ind[i],:]\n",
    "            background[loc[0]:loc[0]+128, loc[1]:loc[1]+128, :] = img\n",
    "\n",
    "            # Save the location of each object as a key-value pair in the meta dictionary.\n",
    "            meta5[j+1][lbls[i]] = i\n",
    "\n",
    "        # Save image as png.\n",
    "        savename = 'stim{0}_{1:03d}'.format(nObjectsPerImg, j+1)\n",
    "        savepath = savedir + '/' + savename + '.png'\n",
    "        \n",
    "        for i in range(nObjectsPerImg):\n",
    "            catg = lbls[i]\n",
    "            loca = np.where(lbls==labels[i])[0][0]\n",
    "            loca = loc_ind[i]\n",
    "            new_savedir = '{}/{}_{}'.format(savedir, catg, loca)\n",
    "            if not os.path.exists(new_savedir):\n",
    "                os.makedirs(new_savedir)\n",
    "\n",
    "            # Copy the file into the appropriate folder.\n",
    "            plt.imsave('{}/{}.png'.format(new_savedir, savename), background)\n",
    "        \n",
    "    np.save(savedir + '/meta{0}'.format(nObjectsPerImg), meta5)\n",
    "    return meta5\n",
    "\n",
    "#meta5 = generate_stimuli(nStims=25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Code Starts Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "with open('imagenet1000.txt') as f:\n",
    "    num2label = eval(f.read())\n",
    "    \n",
    "imsize = 240\n",
    "loader = transforms.Compose([transforms.Scale(imsize), transforms.CenterCrop(imsize), transforms.ToTensor(), normalize])\n",
    "def image_loader(image_name):\n",
    "    \"\"\"load image, returns cuda tensor\"\"\"\n",
    "    image = Image.open(image_name).convert('RGB')\n",
    "\n",
    "    image = loader(image).float()\n",
    "    image = Variable(image, requires_grad=False)\n",
    "    image = image.unsqueeze(0)  #this is for VGG, may not be needed for ResNet\n",
    "    return image#.to_device(device)  #assumes that you're using GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_predictions(output, num2label=num2label, numlines=3):\n",
    "    for idx in output[0].sort(descending=True)[1][:numlines].numpy():\n",
    "        print num2label[idx], output[0][idx].detach().item() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from run_att_net import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "stimdir = '/home/users/akshayj/att_net/imagenet_stimuli/'\n",
    "train_dataset = ImageFolder(stimdir, loader=image_loader)\n",
    "train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=50, shuffle=True)\n",
    "\n",
    "vgg19 = models.vgg19(pretrained=True).to(device)\n",
    "conv1 = nn.Sequential(*list(vgg19.children())[0][:1])\n",
    "convRest = nn.Sequential(*list(vgg19.children())[0][1:])\n",
    "\n",
    "model = AttMLP(128, 576).to(device)\n",
    "m = nn.Upsample(scale_factor=10, mode='nearest')\n",
    "    \n",
    "for step, (x,y) in enumerate(train_data_loader):\n",
    "    b_x = Variable(torch.squeeze(x)).to(device)\n",
    "    \n",
    "    # Extract hidden unit initialization and turn into one-hot\n",
    "    hid = torch.div(y,4).unsqueeze(1).to(device);\n",
    "    hid_1hot = torch.FloatTensor(hid.shape[0], 4).zero_().to(device)    \n",
    "    hid_1hot.scatter_(1, hid, 1)\n",
    "    hid_1hot = hid_1hot.unsqueeze(0)\n",
    "\n",
    "    # conv1 output\n",
    "    conv1_out = conv1(b_x)\n",
    "    \n",
    "    # Output of MLP\n",
    "    output = model(b_x, hid_1hot)\n",
    "    out_reshape = output.view(1,-1,24,24)\n",
    "    \n",
    "    a = torch.squeeze(m(out_reshape))\n",
    "    gain_map = torch.stack((a,)*64, dim=0).transpose(0,1)\n",
    "    \n",
    "    product = torch.mul(conv1_out, gain_map)\n",
    "    \n",
    "    out = convRest(product)\n",
    "    print product.shape, out.shape\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
